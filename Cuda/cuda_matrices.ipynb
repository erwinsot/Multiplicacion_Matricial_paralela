{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CqkthO8k47z",
        "outputId": "464441ba-cfad-4547-fabb-ed09155b8a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-hz4wdmwp\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-hz4wdmwp\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4304 sha256=c68476b4a5d6f14fd2a6f8ed599350b984317896e07edb72d1992b2dd576a5a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-20e_m_jq/wheels/f3/08/cc/e2b5b0e1c92df07dbb50a6f024a68ce090f5e7b2316b41756d\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "__global__ void hello(void)\n",
        "{\n",
        "    printf(\"GPU: Hello!\\n\");\n",
        "}\n",
        "int main(int argc,char **argv)\n",
        "{\n",
        "    printf(\"CPU: Hello!\\n\");\n",
        "    hello<<<1,10>>>();\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja1-xtlcBaiK",
        "outputId": "7740c306-4983-4482-907e-1800ba09a2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_37 -gencode=arch=compute_37,code=sm_37 hello.cu -o hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx5MuN5_Bia6",
        "outputId": "c8abe87b-a11d-4127-88ab-bc83aa889c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "id": "ekis9vNhBmWj",
        "outputId": "e979c570-39a7-4d96-81f0-8bfea5b45b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile codigo1.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <sys/time.h>\n",
        " \n",
        "#define DIM  1024\n",
        "#define XDIM  DIM\n",
        "#define YDIM  DIM\n",
        "#define MATRIXSIZE  XDIM*YDIM\n",
        "#define TILE_SIZE  32           \n",
        "#define NUMTHREADS DIM\n",
        " \n",
        "/**\n",
        " * CUDA Kernel Device code\n",
        " *\n",
        " * Computes the vector addition of A and B into C. The 3 vectors have the same\n",
        " * number of elements numElements.\n",
        " */\n",
        " \n",
        " \n",
        "__global__ void\n",
        "vectorAdd(const int *A, const int *B, int *C, int numElements)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        " \n",
        "    if (i < numElements)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        " \n",
        "/*****************************************************************************/\n",
        "__global__ void\n",
        "multMatrix_globalMemory(double *A, double *B, double *C, int numElements)\n",
        "{\n",
        "    int yOffset;\n",
        "    int i, x;\n",
        "    int y = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    yOffset = y * XDIM;\n",
        " \n",
        "    if (y < numElements)\n",
        "    {\n",
        "        for(x = 0; x < XDIM; x++)\n",
        "        {   *(C + yOffset + x) = 0;\n",
        "            for(i = 0; i < XDIM; i++){\n",
        "                //*(C + yOffset + x) = y;\n",
        "                *(C + yOffset + x) = *(C + yOffset + x) + (*(A + yOffset + i)* (*(B + (i*YDIM) + x )));\n",
        "            }\n",
        "        } \n",
        "    }\n",
        "}\n",
        " \n",
        "/*****************************************************************************/\n",
        "__global__ void\n",
        "multMatrix_sharedMemory(double *A, double *B, double *C, int numElements)\n",
        "{\n",
        "    int x, y, i, j, k;\n",
        "    double p;\n",
        "    //int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    __shared__ double sharedA[TILE_SIZE][TILE_SIZE], sharedB[TILE_SIZE][TILE_SIZE];\n",
        " \n",
        "    int tiles_per_row = DIM/TILE_SIZE;\n",
        "    int globalRowTileOffset = (blockIdx.x * TILE_SIZE * TILE_SIZE * tiles_per_row);\n",
        "    int offsetA, offsetB, offset_x_c, offset_y_c;\n",
        " \n",
        "    y = threadIdx.x / TILE_SIZE;\n",
        "    x = threadIdx.x % TILE_SIZE;\n",
        " \n",
        "    //go through left to right \n",
        "    //other rows of tiles are run by other blocks\n",
        " \n",
        "    for(i = 0;  i < tiles_per_row; i++){\n",
        "        for(k = 0;  k < tiles_per_row; k++){\n",
        "            offsetA = globalRowTileOffset + (k * TILE_SIZE) + (y * tiles_per_row * TILE_SIZE) + x;\n",
        "            sharedA[x][y] = *(A + offsetA);\n",
        "            offsetB = (i * TILE_SIZE) + (k * TILE_SIZE * TILE_SIZE * tiles_per_row) + (y * TILE_SIZE * tiles_per_row) + x;\n",
        "            sharedB[x][y] = *(B + offsetB);\n",
        "            offset_y_c = offsetA / DIM;  //offset to write C\n",
        "            offset_x_c = offsetB % DIM;            \n",
        "            __syncthreads();\n",
        " \n",
        "            p = 0;\n",
        "            for(j = 0; j < TILE_SIZE; j++){\n",
        "                p = p + sharedA[j][y] * sharedB[x][j];\n",
        "            }\n",
        " \n",
        "            __syncthreads();\n",
        "            *(C + (offset_y_c * DIM) + offset_x_c) += p;\n",
        "        }\n",
        "    }\n",
        "}\n",
        " \n",
        " \n",
        "/*****************************************************************************/\n",
        " \n",
        "int multMatrix_cpu(double *A, double *B, double *C){\n",
        "    int i, x, y;\n",
        "    int yOffset;\n",
        " \n",
        "    for(y = 0; y < YDIM; y++){   \n",
        "        yOffset = y * XDIM;\n",
        "        for(x = 0; x < XDIM; x++){   \n",
        "            for(i = 0; i < XDIM; i++){\n",
        "                *(C + yOffset + x) = *(C + yOffset + x) + (*(A + yOffset + i) * (*(B + (i*YDIM) + x )));\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        " \n",
        "/*****************************************************************************/\n",
        " \n",
        "int printMatrix(double *ap)\n",
        "{\n",
        "    int x, y;\n",
        "    for(y = 0; y < YDIM; y++){\n",
        "        printf(\"\\n\");\n",
        "        for(x = 0; x < XDIM; x++){\n",
        "            printf(\"%.1f \\t\", *(ap + (y*XDIM) + x));\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    return 0;\n",
        "}\n",
        " \n",
        " \n",
        "/*****************************************************************************/\n",
        " \n",
        "int matrixCompare(double *C, double *C2){\n",
        "    int x, y;\n",
        "    double diff;\n",
        "    for(y = 0; y < YDIM; y++){\n",
        "        for(x = 0; x < XDIM; x++){   \n",
        "            diff = fabs(*(C + (y * YDIM) + x ) - *(C2 + (y * YDIM) + x ));\n",
        "            if(diff > 1e-5)\n",
        "                return -1;\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\nVerification OK! \\n\");\n",
        "    return 0;\n",
        "}\n",
        " \n",
        "/******************************************************************************\n",
        " * Host main routine\n",
        " */\n",
        "int main(int argc, char *argv[])\n",
        "{   int i, v=1;\n",
        "    int threadsNum, blocksPerGrid, threadsPerBlock;\n",
        "    long elapsed;\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        " \n",
        "    struct timeval tv1, tv2;\n",
        "    \n",
        " \n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = MATRIXSIZE;\n",
        "    size_t size = MATRIXSIZE * sizeof(double);\n",
        "    if(v == 1) printf(\"[Matrix mult of %d elements]    %d x %d \\n\", numElements, DIM, DIM);\n",
        " \n",
        "    // Allocate the host input vector A\n",
        "    double *h_A = (double *)malloc(size);\n",
        " \n",
        "    // Allocate the host input vector B\n",
        "    double *h_B = (double *)malloc(size);\n",
        " \n",
        "    // Allocate the host output vector C\n",
        "    double *h_C = (double *)malloc(size);\n",
        "    double *h_CPU = (double *)malloc(size);\n",
        " \n",
        "    // Verify that allocations succeeded\n",
        "    if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    // Initialize the host input vectors\n",
        "    \n",
        "    for(i = 0; i < MATRIXSIZE; i++){\n",
        "        *(h_A + i) = rand() & 0xF;\n",
        "        *(h_B + i) = rand() & 0xF;        \n",
        "        *(h_C + i) = 0;\n",
        "    }\n",
        "    //printMatrix(h_A);\n",
        "    //printMatrix(h_B);\n",
        "    printf(\"\\nStarting CPU multiplication \");  fflush(stdout);\n",
        "    gettimeofday(&tv1,NULL);\n",
        "    multMatrix_cpu(h_A, h_B, h_CPU);\n",
        "    gettimeofday(&tv2,NULL);\n",
        "    elapsed = ((tv2.tv_sec - tv1.tv_sec) * 1000000) + (tv2.tv_usec - tv1.tv_usec);    \n",
        "    printf(\"\\nCPU multiplication finished in %ld microseconds\\n\", elapsed);  fflush(stdout);\n",
        "    \n",
        "    // Allocate the device input vector A\n",
        "    double *d_A = NULL;\n",
        "    err = cudaMalloc((void **)&d_A, size);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    // Allocate the device input vector B\n",
        "    double *d_B = NULL;\n",
        "    err = cudaMalloc((void **)&d_B, size);\n",
        " \n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    // Allocate the device output vector C\n",
        "    double *d_C = NULL;\n",
        "    err = cudaMalloc((void **)&d_C, size);\n",
        " \n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "    // device memory\n",
        "    \n",
        "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        " \n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        " \n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    err = cudaMemcpy(d_C, h_C, size, cudaMemcpyHostToDevice);\n",
        " \n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        " \n",
        "    /****** Launch the Kernel *******/\n",
        "    threadsNum = DIM;\n",
        "    threadsPerBlock = 64;\n",
        "    blocksPerGrid = threadsNum / threadsPerBlock;\n",
        "    printf(\"\\nCUDA kernel launch with %d blocks of %d threads\", blocksPerGrid, threadsPerBlock); fflush(stdout);\n",
        "    gettimeofday(&tv1,NULL);\n",
        "    multMatrix_globalMemory<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to launch kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    \n",
        "    gettimeofday(&tv2,NULL);\n",
        "    elapsed = ((tv2.tv_sec - tv1.tv_sec) * 1000000) + (tv2.tv_usec - tv1.tv_usec);\n",
        "    printf(\"\\nGPU multiplication executed in %ld microseconds\", elapsed);  fflush(stdout);\n",
        " \n",
        "    if(matrixCompare(h_C, h_CPU) == -1)\n",
        "        printf(\"\\nNot equal\");\n",
        "    for(i = 0; i < MATRIXSIZE; i++){ \n",
        "        *(h_C + i) = 0;  //clean C\n",
        "    }\n",
        "    err = cudaMemcpy(d_C, h_C, size, cudaMemcpyHostToDevice);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    /****** Launch the tiled Kernel *******/\n",
        "    threadsPerBlock = TILE_SIZE * TILE_SIZE;\n",
        "    blocksPerGrid = (DIM / TILE_SIZE);\n",
        "    printf(\"\\nCUDA kernel launch with %d blocks of %d threads\", blocksPerGrid, threadsPerBlock); fflush(stdout);\n",
        "    gettimeofday(&tv1,NULL);\n",
        "    multMatrix_sharedMemory<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to launch kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    gettimeofday(&tv2,NULL);\n",
        "    elapsed = ((tv2.tv_sec - tv1.tv_sec) * 1000000) + (tv2.tv_usec - tv1.tv_usec);\n",
        "    printf(\"\\nGPU tiled multiplication executed in %ld  microseconds\", elapsed);  fflush(stdout);\n",
        "    \n",
        "    if(matrixCompare(h_C, h_CPU) == -1)\n",
        "        printf(\"\\nNot equal\");\n",
        "    \n",
        "    // Free device global memory\n",
        "    err = cudaFree(d_A);\n",
        " \n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    err = cudaFree(d_B);\n",
        " \n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    err = cudaFree(d_C);\n",
        " \n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        "    \n",
        "    //printMatrix(h_C);\n",
        "    //printMatrix(h_CPU);\n",
        " \n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    free(h_CPU);\n",
        " \n",
        "    // Reset the device and exit\n",
        "    // cudaDeviceReset causes the driver to clean up all state. While\n",
        "    // not mandatory in normal operation, it is good practice.  It is also\n",
        "    // needed to ensure correct operation when the application is being\n",
        "    // profiled. Calling cudaDeviceReset causes all profile data to be\n",
        "    // flushed before the application exits\n",
        "    err = cudaDeviceReset();\n",
        " \n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        " \n",
        " \n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y-BJSOAzYMc",
        "outputId": "d6db41bf-7479-4356-91bd-24a5f45e586e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing codigo1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_37 -gencode=arch=compute_37,code=sm_37 codigo1.cu -o cod1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY76eC-8zz1V",
        "outputId": "56450d0b-4226-4970-b337-d259867f0ac2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./cod1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PskXYb13z824",
        "outputId": "3b1c3fab-fcab-45bd-d7ba-5aa0d80fdf56"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Matrix mult of 1048576 elements]    1024 x 1024 \n",
            "\n",
            "Starting CPU multiplication \n",
            "CPU multiplication finished in 10023756 microseconds\n",
            "\n",
            "CUDA kernel launch with 16 blocks of 64 threads\n",
            "GPU multiplication executed in 552175 microseconds\n",
            "Verification OK! \n",
            "\n",
            "CUDA kernel launch with 32 blocks of 1024 threads\n",
            "GPU tiled multiplication executed in 26850  microseconds\n",
            "Verification OK! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /usr/local/cuda-11.2/samples/1_Utilities/deviceQuery/\n",
        "!ls\n",
        "!make\n",
        "!./deviceQuery\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9HlkyMQ9Owk",
        "outputId": "c5383cc1-19da-430c-8bdf-600a61062fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda-11.2/samples/1_Utilities/deviceQuery\n",
            "deviceQuery.cpp  Makefile  NsightEclipse.xml  readme.txt\n",
            "/usr/local/cuda-11.2/bin/nvcc -ccbin g++ -I../../common/inc  -m64    --threads 0 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86 -o deviceQuery.o -c deviceQuery.cpp\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/cuda-11.2/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86 -o deviceQuery deviceQuery.o \n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n",
            "./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          11.2 / 11.2\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15110 MBytes (15843721216 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total shared memory per multiprocessor:        65536 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Managed Memory:                Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.2, CUDA Runtime Version = 11.2, NumDevs = 1\n",
            "Result = PASS\n"
          ]
        }
      ]
    }
  ]
}